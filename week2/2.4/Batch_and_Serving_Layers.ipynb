{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset -f -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division \n",
    "import numpy as np\n",
    "import json\n",
    "import avro.io\n",
    "import avro.schema\n",
    "from avro.datafile import DataFileReader, DataFileWriter\n",
    "from avro.io import DatumReader, DatumWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from nltk.corpus import names\n",
    "from numpy.random import choice, shuffle, random\n",
    "from data_gen import get_datum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Architecture\n",
    "    3 Layers - Batch Layer, Serving Layer and Speed Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The master dataset in the Lambda Architecture serves as the source of truth for your Big Data system. Errors at the serving and speed layers can be corrected, but corruption of the master dataset is irreparable](https://s3-us-west-2.amazonaws.com/dsci6007/assets/fig2-1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema\n",
    "    Edges and Nodes Knowldge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 6.3](lab_2_4_fact_based_modeling.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ItemID = [{\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"ItemID\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"item_number\", \"type\": [\"int\",\"string\"]}\n",
    "        ]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UserID = [{\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"UserID\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"user_number\", \"type\": [\"int\",\"string\"]}\n",
    "        ]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I may have to also allow for \"null\" so emtpy properties are permitable \n",
    "UserProperties = [\n",
    "    {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"Location\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"city\",    \"type\": \"string\"},\n",
    "            {\"name\": \"state\",   \"type\": \"string\"},\n",
    "            {\"name\": \"country\", \"type\": \"string\"}\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"enum\",\n",
    "        \"name\": \"GenderType\",\n",
    "        \"symbols\": [\"MALE\", \"FEMALE\"]\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"UserName\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"name\", \"type\": \"string\"}\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"UserProperty\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"userID\",\"type\": \"UserID\"},\n",
    "            \n",
    "            {\n",
    "                \"name\": \"property\",\n",
    "                \"type\": [\n",
    "                    {\n",
    "                        \"type\": \"record\",\n",
    "                        \"name\": \"UserPropertyValue1\",\n",
    "                        \"fields\": [{\"name\": \"user_name\", \"type\": \"UserName\"}]\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"record\",\n",
    "                        \"name\": \"UserPropertyValue2\",\n",
    "                        \"fields\": [{\"name\": \"gender\",    \"type\": \"GenderType\"}]\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"record\",\n",
    "                        \"name\": \"UserPropertyValue3\",\n",
    "                        \"fields\": [{\"name\": \"location\",  \"type\": \"Location\"}]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ItemProperties = [\n",
    "    {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"ItemProperty\",\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"name\": \"item_id\",\n",
    "                \"type\": \"ItemID\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"property\",\n",
    "                \"type\": [\n",
    "                    {\n",
    "                        \"type\": \"record\",\n",
    "                        \"name\": \"ItemPropertyValue1\",\n",
    "                        \"fields\": [{\"name\": \"item_name\", \"type\": \"string\"}]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PurchaseEdge = {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"PurchaseEdge\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"userID\", \"type\": \"UserID\"},\n",
    "            {\"name\": \"item_id\", \"type\": \"ItemID\"},\n",
    "            {\"name\": \"purchase_time\", \"type\": \"int\"}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ReviewEdge = {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"ReviewEdge\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"userID\",   \"type\": \"UserID\"},\n",
    "            {\"name\": \"item_id\",   \"type\": \"ItemID\"},\n",
    "            {\"name\": \"review\", \"type\": \"string\"},\n",
    "            {\"name\": \"rating\", \"type\": [\"int\",'null']}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = [\n",
    "    {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"Pedigree\",\n",
    "        \"fields\": [{\"name\": \"true_as_of_secs\", \"type\": \"int\"}]\n",
    "    },\n",
    "    {\n",
    "        \"namespace\": \"amazon.avsc\",\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"Data\",\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"name\": \"pedigree\",\n",
    "                \"type\": \"Pedigree\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"dataunit\",\n",
    "                \"type\": [\n",
    "                    {\n",
    "                        \"type\": \"record\",\n",
    "                        \"name\": \"DataUnit1\",\n",
    "                        \"fields\": [{\"name\": \"user_property\", \"type\": \"UserProperty\"}]\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"record\",\n",
    "                        \"name\": \"DataUnit2\",\n",
    "                        \"fields\": [{\"name\": \"item_property\", \"type\": \"ItemProperty\"}]\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"record\",\n",
    "                        \"name\": \"DataUnit3\",\n",
    "                        \"fields\": [{\"name\": \"purchase_edge\", \"type\": \"PurchaseEdge\"}]\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"record\",\n",
    "                        \"name\": \"DataUnit4\",\n",
    "                        \"fields\": [{\"name\": \"review_edge\", \"type\": \"ReviewEdge\"}]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_Data_to_masterSet(N,get_datum,file_name):\n",
    "    writer = DataFileWriter(open(file_name, \"w\"), DatumWriter(), schema)\n",
    "    n = 0\n",
    "    while n < N:\n",
    "        writer.append(get_datum.next())\n",
    "        n += 1\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nodes = UserID + ItemID\n",
    "Edges = [PurchaseEdge, ReviewEdge]\n",
    "schema = avro.schema.parse(json.dumps(Nodes + Edges +  UserProperties +  ItemProperties + Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# userID bank only needs to be saved to file once !\n",
    "#save_to_file = True\n",
    "gen = get_datum(save_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: This code only needs to run once.\n",
    "N_datum = 40000\n",
    "data_file = \"amazon_data_master.avro\"\n",
    "insert_Data_to_masterSet(N_datum,gen,data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka: Send New Data to Master Set and Speed Layer\n",
    "    upload consumer ids and generate new data in Kafka - producer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka: Overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io, random, threading, logging, time\n",
    "import simplejson as json\n",
    "from data_gen import get_datum\n",
    "\n",
    "from kafka.client   import KafkaClient\n",
    "from kafka.consumer import KafkaConsumer\n",
    "from kafka.producer import SimpleProducer\n",
    "\n",
    "KAFKA_TOPIC = 'amazon-topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default settings: do not generate new user ids, upload and use existing ides\n",
    "gen = get_datum(save_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka - Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kafka pluin for spark streaming will only accept utf-8\n",
    "# CAN'T SEND BINARY CODE\n",
    "\n",
    "class Producer(threading.Thread):\n",
    "    '''Produces users and publishes them to Kafka topic.'''\n",
    "    daemon = True\n",
    "    def run(self):\n",
    "        # default settings: do not generate new user ids, upload and use existing ides\n",
    "        gen = get_datum()\n",
    "        client = KafkaClient('localhost:9092')\n",
    "        producer = SimpleProducer(client)\n",
    "        \n",
    "        while True:\n",
    "            raw_bytes = json.dumps(gen.next()).encode('utf-8')\n",
    "            producer.send_messages(KAFKA_TOPIC, raw_bytes)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p= Producer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Streaming - Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting amazon_kafka.py\n"
     ]
    }
   ],
   "source": [
    "%%file amazon_kafka.py\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import happybase\n",
    "import simplejson as json\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "def get_purchases(datum):\n",
    "    item = datum['dataunit']['purchase_edge']['item_id']['item_number']\n",
    "    user = datum['dataunit']['purchase_edge']['userID']['user_number']\n",
    "    true_as_of_secs = datum['pedigree']['true_as_of_secs']\n",
    "    return user, item,true_as_of_secs\n",
    "\n",
    "def get_user_gender(gender_datum):\n",
    "    \n",
    "    gender  = gender_datum['dataunit']['user_property']['property']['gender']\n",
    "    user_id = gender_datum['dataunit']['user_property']['userID']['user_number']\n",
    "    ts      = gender_datum['pedigree']['true_as_of_secs']\n",
    "    \n",
    "    return user_id, gender, ts\n",
    "\n",
    "def get_user_location(location_datum):\n",
    "    \n",
    "    city    = location_datum['dataunit']['user_property']['property']['location']['city']\n",
    "    state   = location_datum['dataunit']['user_property']['property']['location']['state']\n",
    "    country = location_datum['dataunit']['user_property']['property']['location']['country']\n",
    "    user_id = location_datum['dataunit']['user_property']['userID']['user_number']\n",
    "    ts      = location_datum['pedigree']['true_as_of_secs']\n",
    "    \n",
    "    return user_id, city,state,country, ts\n",
    "\n",
    "def get_user_name(name_datum):\n",
    "    \n",
    "    name    = name_datum['dataunit']['user_property']['property']['user_name']['name']\n",
    "    user_id = name_datum['dataunit']['user_property']['userID']['user_number']\n",
    "    ts      = name_datum['pedigree']['true_as_of_secs']\n",
    "    \n",
    "    #     return user_id, name, ts\n",
    "    return  user_id, name, ts\n",
    "\n",
    "def get_itemName(item_datum):\n",
    "    ID     = item_datum['dataunit']['item_property']['item_id']['item_number']\n",
    "    name    = item_datum['dataunit']['item_property']['property']['item_name']\n",
    "    ts      = item_datum['pedigree']['true_as_of_secs']\n",
    "    return ID, name, ts\n",
    "\n",
    "def get_review_rating(review_datum):\n",
    "    user_id = review_datum['dataunit']['review_edge']['userID']['user_number']\n",
    "    item_id = review_datum['dataunit']['review_edge']['item_id']['item_number']\n",
    "    rating  = review_datum['dataunit']['review_edge']['rating']\n",
    "    review  = review_datum['dataunit']['review_edge']['review']\n",
    "    ts      = review_datum['pedigree']['true_as_of_secs']\n",
    "    return user_id, item_id, rating, ts, review    \n",
    "\n",
    "def partition_data(datum):\n",
    "    datatype = datum['dataunit'].keys()[0]\n",
    "    if datatype.endswith('property'):\n",
    "        # returns partitioned properties\n",
    "        return '/'.join((datatype, datum['dataunit'][datatype]['property'].keys()[0])), datum\n",
    "    else:\n",
    "        # returns edges\n",
    "        return datatype, datum \n",
    "    \n",
    "def prep_data_Hbase(datum):\n",
    "    '''returns formated datum'''\n",
    "    def function_call(label):\n",
    "        if label == \"user_name\":\n",
    "            return get_user_name\n",
    "        elif label == 'gender':\n",
    "            return get_user_gender\n",
    "        elif label ==\"location\": \n",
    "            return get_user_location\n",
    "        elif label == \"purchase_edge\":\n",
    "            return get_purchases\n",
    "        elif label == \"review_edge\":\n",
    "            return get_review_rating\n",
    "        else:\n",
    "            return get_itemName\n",
    "        \n",
    "    if \"property\" in datum[0]:\n",
    "        label = datum[0].split(\"/\")[1]\n",
    "    else:\n",
    "        label = datum[0]\n",
    "        \n",
    "    func = function_call(label)\n",
    "    \n",
    "    return func(datum[1]),label \n",
    "                \n",
    "def insert_data_hbase(datum,label):\n",
    "    '''inserts data into hbase in batchs - one insert per property/edge'''\n",
    "    table = connection.table(label)\n",
    "    if label == \"user_name\":\n",
    "        table.put(datum[0], {'d:name'   : datum[1], \n",
    "                                  'd:ts' : str(datum[2])})\n",
    "        return \"insert\"\n",
    "    elif label == \"gender\":\n",
    "        table.put(datum[0], {'d:gender' : datum[1],\n",
    "                                'd:ts'   : str(datum[2])})\n",
    "        return \"insert\"\n",
    "    elif label == \"location\":\n",
    "        table.put(datum[0], {'d:city'     : datum[1],\n",
    "                                'd:state'  : datum[2],\n",
    "                                'd:country': datum[3],\n",
    "                                'd:ts'     : str(datum[4])})\n",
    "        return \"insert\"\n",
    "    elif label == \"purchase_edge\":\n",
    "        table.put(datum[0], {'d:item_id': datum[1],\n",
    "                                'd:ts'     : str(datum[2])})\n",
    "        return \"insert\"\n",
    "    elif label == \"review_edge\":\n",
    "        table.put(datum[0], {'d:item_id': datum[1],\n",
    "                                'd:rating' : str(datum[2]),\n",
    "                                'd:ts'     : str(datum[3]),\n",
    "                                'd:review' : str(datum[4])})\n",
    "        return \"insert\"\n",
    "    else:\n",
    "        table.put(datum[0], {'d:name'   : datum[1], \n",
    "                              'd:ts'     : str(datum[2])})\n",
    "        return \"insert\"\n",
    "        \n",
    "def updateFunction(newValues, runningCount):\n",
    "    if runningCount is None:\n",
    "        runningCount = 0\n",
    "    return sum(newValues, runningCount)  \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    \n",
    "    sc = SparkContext(appName=\"Amazon-Data\")\n",
    "    ssc = StreamingContext(sc, 1)\n",
    "    ssc.checkpoint('ckpt')\n",
    "    connection = happybase.Connection(host = 'localhost')\n",
    "    zkQuorum, topic = 'localhost:2181' , 'amazon-topic' # use localhost that topic is created on!\n",
    "    kvs = KafkaUtils.createStream(ssc, zkQuorum, \"spark-streaming-consumer\", {topic: 1})\n",
    "    \n",
    "    # keep count of fact labels \n",
    "#     kvs.window(windowDuration=4,slideDuration=2)\\\n",
    "#        .map(lambda tup: partition_data(json.loads(tup[1])))\\\n",
    "#        .map(lambda tup: (tup[0],1))\\\n",
    "#        .updateStateByKey(updateFunction).pprint()\n",
    "    \n",
    "    # keep count of fact labels \n",
    "    kvs.window(windowDuration=4,slideDuration=2)\\\n",
    "       .map(lambda tup: partition_data(json.loads(tup[1])))\\\n",
    "       .map(lambda tup: prep_data_Hbase(tup))\\\n",
    "       .saveAsTextFiles(prefix = \"sparkdata/sparkdata\")\n",
    "            \n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$SPARK_HOME/bin/spark-submit --packages org.apache.spark:spark-streaming-kafka_2.10:1.5.1 /Users/Alexander/DSCI6007-student/week2/2.4/amazon_kafka.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (None, u'{\"dataunit\": {\"item_property\": {\"item_id\": {\"item_number\": \"136639784072844879_2015_21_33\"}, \"property\": {\"item_name\": \"garmin-nuvi-880\"}}}, \"pedigree\": {\"true_as_of_secs\": 1444934461}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_data_hbase(datum,label):\n",
    "    '''inserts data into hbase in batchs - one insert per property/edge'''\n",
    "    table = connection.table(label)\n",
    "    if label == \"user_name\":\n",
    "        table.put(datum[0], {'d:name'   : datum[1], \n",
    "                                  'd:ts' : str(datum[2])})\n",
    "        return \"insert\"\n",
    "    elif label == \"gender\":\n",
    "        table.put(datum[0], {'d:gender' : datum[1],\n",
    "                                'd:ts'   : str(datum[2])})\n",
    "        return \"insert\"\n",
    "    elif label == \"location\":\n",
    "        table.put(datum[0], {'d:city'     : datum[1],\n",
    "                                'd:state'  : datum[2],\n",
    "                                'd:country': datum[3],\n",
    "                                'd:ts'     : str(datum[4])})\n",
    "        return \"insert\"\n",
    "    elif label == \"purchase_edge\":\n",
    "        table.put(datum[0], {'d:item_id': datum[1],\n",
    "                                'd:ts'     : str(datum[2])})\n",
    "        return \"insert\"\n",
    "    elif label == \"review_edge\":\n",
    "        table.put(datum[0], {'d:item_id': datum[1],\n",
    "                                'd:rating' : str(datum[2]),\n",
    "                                'd:ts'     : str(datum[3]),\n",
    "                                'd:review' : str(datum[4])})\n",
    "        return \"insert\"\n",
    "    else:\n",
    "        table.put(datum[0], {'d:name'   : datum[1], \n",
    "                              'd:ts'     : str(datum[2])})\n",
    "        return \"insert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prototype Spark Streaming Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_gen import get_datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import simplejson as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_data = get_datum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datum = [g_data.next() for _ in xrange(0,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataunit': {'user_property': {'property': {'user_name': {'name': u'Rosaline Franklyn'}},\n",
       "    'userID': {'user_number': '136638102498064138_2015_22_50'}}},\n",
       "  'pedigree': {'true_as_of_secs': 1444635102}}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First map will have to be a json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('item_property/item_name',\n",
       "  {'dataunit': {'item_property': {'item_id': {'item_number': '136638094663214138_2015_22_37'},\n",
       "     'property': {'item_name': 'zune-hd-32gb-platinum'}}},\n",
       "   'pedigree': {'true_as_of_secs': 1444961136}}),\n",
       " ('user_property/location',\n",
       "  {'dataunit': {'user_property': {'property': {'location': {'city': u'Ullrichstad',\n",
       "       'country': 'USA',\n",
       "       'state': u'AR'}},\n",
       "     'userID': {'user_number': '136638094663082048_2015_22_37'}}},\n",
       "   'pedigree': {'true_as_of_secs': 1444886718}}),\n",
       " ('user_property/user_name',\n",
       "  {'dataunit': {'user_property': {'property': {'user_name': {'name': u'Meyer Clifford'}},\n",
       "     'userID': {'user_number': '136638094662988751_2015_22_37'}}},\n",
       "   'pedigree': {'true_as_of_secs': 1444639391}})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda fact: fact)\\\n",
    "   .map(lambda fact: partition_data(fact))\\\n",
    "   .map(lambda tup : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tup = ('user_property/gender',\n",
    "  {'dataunit': {'user_property': {'property': {'gender': 'FEMALE'},\n",
    "     'userID': {'user_number': '136636589919406200_2015_04_49'}}},\n",
    "   'pedigree': {'true_as_of_secs': 1444366238}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_current_property(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_current_property(values):\n",
    "    '''scans property time stampts and selects the most current property '''\n",
    "    timestamp = -1\n",
    "    timestamps = dict()\n",
    "    if \"user_property\" in tup[0]:\n",
    "        for prop in values:\n",
    "            timestamps[prop[timestamp]]=prop[:timestamp]\n",
    "        max_ts = max(timestamps.keys())\n",
    "\n",
    "        if len(timestamps[max_ts]) == 1:\n",
    "            return (timestamps[max_ts][0],max_ts)\n",
    "        elif len(timestamps[max_ts]) == 2:\n",
    "            return (timestamps[max_ts][0],timestamps[max_ts][1],max_ts)\n",
    "        else:\n",
    "            return (timestamps[max_ts][0],timestamps[max_ts][1],timestamps[max_ts][2],max_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_good_data(datum, schema=schema):\n",
    "    return avro.io.validate(schema, datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat = {\"pedigree\": {\"true_as_of_secs\": 1111111},\n",
    "       \"dataunit\": {\"seller_edge\":{\"seller_id\" : {\"user_number\": 101},\n",
    "                                     \"buyer_id\": {\"user__number\": 202},\n",
    "                                       \"rating\": 4}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_good_data(dat, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Virtical Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cStringIO import StringIO\n",
    "import fastavro\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path to generated amazon data\n",
    "file_path = \"/Users/Alexander/DSCI6007-student/week2/2.4/amazon_data_master.avro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deserialize data\n",
    "reader = DataFileReader(open(file_path, \"r\"), DatumReader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tell Spark to distribute data\n",
    "data = sc.parallelize(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sanity points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should have 60,000 data units \n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'dataunit': {u'item_property': {u'item_id': {u'item_number': u'136639652273340198_2015_17_53'},\n",
       "    u'property': {u'item_name': u'garmin-nuvi-660'}}},\n",
       "  u'pedigree': {u'true_as_of_secs': 1445245982}}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should have intented structure \n",
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_data(datum):\n",
    "    print datum\n",
    "    datatype = datum['dataunit'].keys()[0]\n",
    "    if datatype.endswith('property'):\n",
    "        # returns partitioned properties\n",
    "        return '/'.join((datatype, datum['dataunit'][datatype]['property'].keys()[0])), datum\n",
    "    else:\n",
    "        # returns edges\n",
    "        return datatype, datum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partitioned_json = data.map(partition_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'item_property/item_name',\n",
       "  {u'dataunit': {u'item_property': {u'item_id': {u'item_number': u'136639652273340198_2015_17_53'},\n",
       "     u'property': {u'item_name': u'garmin-nuvi-660'}}},\n",
       "   u'pedigree': {u'true_as_of_secs': 1445245982}}),\n",
       " (u'item_property/item_name',\n",
       "  {u'dataunit': {u'item_property': {u'item_id': {u'item_number': u'136639652273325460_2015_17_53'},\n",
       "     u'property': {u'item_name': u'apple-ipod-shuffle-third-generation-4gb-black'}}},\n",
       "   u'pedigree': {u'true_as_of_secs': 1444950936}}),\n",
       " (u'user_property/location',\n",
       "  {u'dataunit': {u'user_property': {u'property': {u'location': {u'city': u'Iron Ridge',\n",
       "       u'country': u'USA',\n",
       "       u'state': u'Wisconsin'}},\n",
       "     u'userID': {u'user_number': u'136639652273210078_2015_17_53'}}},\n",
       "   u'pedigree': {u'true_as_of_secs': 1445023584}})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioned_json.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'item_property/item_name'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioned_json.take(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cache data into RAM for quick access\n",
    "# will be performing as many transformations as there are properties + edges \n",
    "#partitioned_json.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sanity check \n",
    "# make sure that only the desired partitions were created\n",
    "# lambda function pulls the key from all dataums\n",
    "partition_names = partitioned_json.map(lambda t: t[0]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check the partition names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'user_property/user_name',\n",
       " u'item_property/item_name',\n",
       " u'user_property/location',\n",
       " u'user_property/gender',\n",
       " u'purchase_edge',\n",
       " u'review_edge']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<type 'int'>, {u'user_property/location': 4036, u'review_edge': 339, u'purchase_edge': 1788, u'user_property/gender': 3992, u'item_property/item_name': 17884, u'user_property/user_name': 11961})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count on each partition \n",
    "partitioned_json.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# orgainize properties into folders\n",
    "# NOTE: This code only needs to run once!\n",
    "for p in partition_names:\n",
    "    path = \"../Amazon_Lambda_Arch/master/{}\".format(p)\n",
    "    if os.path.exists(path):\n",
    "        print \"{} exists\".format(path)\n",
    "    else:\n",
    "        partitioned_json.filter(lambda t: t[0] == p).values().saveAsPickleFile(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting a query into pre-computation and on-the-fly components\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{batch view} &= function(\\text{all data})\\\\\n",
    "\\text{query} &= function(\\text{batch view})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "![Figure 6.3](06fig03_alt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create Batch Views\n",
    "    Here we will preprocess the data--normalizing, removing duplicates--and create batch views\n",
    "    \n",
    "    1. We will upload edge data and property data\n",
    "    2. We will use 'get' functions to filter the data out of the data units\n",
    "    3. We will use the filtered data to create 2 batch view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Purchase Edge for batch views\n",
    "    NOTE: All objects with prefix 'pickled' are raw data \n",
    "          that needs to be reformated with a function for a view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DAG: Pre-Processing  Data\n",
    "    User name and review are used as examples for the general flow for processing properties and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed gvmagic.py. To use it, type:\n",
      "  %load_ext gvmagic\n"
     ]
    }
   ],
   "source": [
    "%install_ext https://raw.github.com/cjdrake/ipython-magic/master/gvmagic.py\n",
    "%load_ext gvmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"538pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 538.03 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 534.026,-256 534.026,4 -4,4\"/>\n",
       "<!-- Data1 -->\n",
       "<g id=\"node1\" class=\"node\"><title>Data1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"230.43,-180 117.029,-180 117.029,-144 230.43,-144 230.43,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"173.729\" y=\"-164.8\" font-family=\"Times,serif\" font-size=\"14.00\">Data:</text>\n",
       "<text text-anchor=\"middle\" x=\"173.729\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">User Name Units</text>\n",
       "</g>\n",
       "<!-- get_user_name -->\n",
       "<g id=\"node3\" class=\"node\"><title>get_user_name</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"208.122,-108 7.33653,-108 7.33653,-72 208.122,-72 208.122,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.729\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Input:</text>\n",
       "<text text-anchor=\"middle\" x=\"107.729\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\"> (Data Unit) &#45;&gt; (user_id,name,ts)</text>\n",
       "</g>\n",
       "<!-- Data1&#45;&gt;get_user_name -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>Data1&#45;&gt;get_user_name</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.415,-143.697C149.422,-135.22 139.658,-124.864 130.907,-115.583\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.263,-112.979 123.856,-108.104 128.17,-117.781 133.263,-112.979\"/>\n",
       "</g>\n",
       "<!-- Data2 -->\n",
       "<g id=\"node2\" class=\"node\"><title>Data2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"406.099,-180 281.36,-180 281.36,-144 406.099,-144 406.099,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"343.729\" y=\"-164.8\" font-family=\"Times,serif\" font-size=\"14.00\">Data:</text>\n",
       "<text text-anchor=\"middle\" x=\"343.729\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">Review Edge Units</text>\n",
       "</g>\n",
       "<!-- get_review_edge -->\n",
       "<g id=\"node4\" class=\"node\"><title>get_review_edge</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"529.823,-108 225.636,-108 225.636,-72 529.823,-72 529.823,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"377.729\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Input:</text>\n",
       "<text text-anchor=\"middle\" x=\"377.729\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\"> (Data Unit) &#45;&gt; (user_id, item_id, rating, ts, review)</text>\n",
       "</g>\n",
       "<!-- Data2&#45;&gt;get_review_edge -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>Data2&#45;&gt;get_review_edge</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M352.134,-143.697C356.004,-135.728 360.681,-126.1 364.973,-117.264\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"368.201,-118.629 369.422,-108.104 361.904,-115.57 368.201,-118.629\"/>\n",
       "</g>\n",
       "<!-- Output_name -->\n",
       "<g id=\"node5\" class=\"node\"><title>Output_name</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"215.689,-36 -0.229982,-36 -0.229982,-0 215.689,-0 215.689,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.729\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">Output: [user_id, name, timestamp]</text>\n",
       "</g>\n",
       "<!-- get_user_name&#45;&gt;Output_name -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>get_user_name&#45;&gt;Output_name</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.729,-71.6966C107.729,-63.9827 107.729,-54.7125 107.729,-46.1124\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.23,-46.1043 107.729,-36.1043 104.23,-46.1044 111.23,-46.1043\"/>\n",
       "</g>\n",
       "<!-- Output_review -->\n",
       "<g id=\"node6\" class=\"node\"><title>Output_review</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"509.403,-36 246.056,-36 246.056,-0 509.403,-0 509.403,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"377.729\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">Output: [user_id, item_id, rating, ts, review]</text>\n",
       "</g>\n",
       "<!-- get_review_edge&#45;&gt;Output_review -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>get_review_edge&#45;&gt;Output_review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M377.729,-71.6966C377.729,-63.9827 377.729,-54.7125 377.729,-46.1124\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"381.23,-46.1043 377.729,-36.1043 374.23,-46.1044 381.23,-46.1043\"/>\n",
       "</g>\n",
       "<!-- Master_Data -->\n",
       "<g id=\"node7\" class=\"node\"><title>Master_Data</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"303.034,-252 214.425,-252 214.425,-216 303.034,-216 303.034,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.729\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\">Master_Data</text>\n",
       "</g>\n",
       "<!-- Master_Data&#45;&gt;Data1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>Master_Data&#45;&gt;Data1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M237.718,-215.697C227.013,-206.881 213.84,-196.032 202.234,-186.474\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.443,-183.76 194.499,-180.104 199.993,-189.163 204.443,-183.76\"/>\n",
       "</g>\n",
       "<!-- Master_Data&#45;&gt;Data2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>Master_Data&#45;&gt;Data2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M279.741,-215.697C290.446,-206.881 303.619,-196.032 315.225,-186.474\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"317.466,-189.163 322.96,-180.104 313.016,-183.76 317.466,-189.163\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%dot digraph {\n",
    "    node [shape=box]\n",
    "    \n",
    "    Data1  [label = \"Data:\\nUser Name Units\"]\n",
    "    Data2  [label = \"Data:\\nReview Edge Units\"]\n",
    "    get_user_name     [label = \"Input:\\n (Data Unit) -> (user_id,name,ts)\"]\n",
    "    get_review_edge   [label = \"Input:\\n (Data Unit) -> (user_id, item_id, rating, ts, review)\"]\n",
    "    Output_name   [label = \"Output: [user_id, name, timestamp]\"]\n",
    "    Output_review [label = \"Output: [user_id, item_id, rating, ts, review]\"]\n",
    "    \n",
    "    Master_Data -> Data1;\n",
    "    Master_Data -> Data2;\n",
    "    Data1-> get_user_name;\n",
    "    Data2 -> get_review_edge;\n",
    "    get_user_name ->Output_name;\n",
    "    get_review_edge -> Output_review;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Upload purchase edge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load and distribute pickle files into spark\n",
    "# create RDD\n",
    "pickled_purchases = sc.pickleFile(\"/Users/Alexander/DSCI6007-student/week2/Amazon_Lambda_Arch/master/purchase_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'dataunit': {u'purchase_edge': {u'item_id': {u'item_number': u'136639652273322821_2015_17_53'},\n",
       "    u'purchase_time': 1445014275,\n",
       "    u'userID': {u'user_number': u'136639652273091089_2015_17_53'}}},\n",
       "  u'pedigree': {u'true_as_of_secs': 1444690262}}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_purchases.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "distinct_purchases = pickled_purchases.map(json.dumps).distinct().map(json.loads)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1788"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_purchases.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1788"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no duplicates\n",
    "distinct_purchases.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 86400, 'h': 3600, 'm': 2419200, 'w': 604800}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granularity = {'h': 60 * 60}\n",
    "granularity['d'] = granularity['h'] * 24\n",
    "granularity['w'] = granularity['d'] * 7\n",
    "granularity['m'] = granularity['w'] * 4\n",
    "granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hourly(datum):\n",
    "    item = datum['dataunit']['purchase_edge']['item_id']['item_number']\n",
    "    user = datum['dataunit']['purchase_edge']['userID']['user_number']\n",
    "    true_as_of_secs = datum['pedigree']['true_as_of_secs']\n",
    "    # return key, value\n",
    "    return user, item, 'h', true_as_of_secs - true_as_of_secs % granularity['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dayly(datum):\n",
    "    item = datum['dataunit']['purchase_edge']['item_id']['item_number']\n",
    "    user = datum['dataunit']['purchase_edge']['userID']['user_number']\n",
    "    true_as_of_secs = datum['pedigree']['true_as_of_secs']\n",
    "    # return key, value\n",
    "    return user, item, 'd', true_as_of_secs - true_as_of_secs % granularity['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_purchases(datum):\n",
    "    item = datum['dataunit']['purchase_edge']['item_id']['item_number']\n",
    "    user = datum['dataunit']['purchase_edge']['userID']['user_number']\n",
    "    true_as_of_secs = datum['pedigree']['true_as_of_secs']\n",
    "    return user, item,true_as_of_secs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dayly_rollup = pickled_purchases.map(dayly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purchaseEdge = pickled_purchases.map(get_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'136639652273091089_2015_17_53',\n",
       "  u'136639652273322821_2015_17_53',\n",
       "  1444690262),\n",
       " (u'136639652273079979_2015_17_53',\n",
       "  u'136639652273318351_2015_17_53',\n",
       "  1444797361),\n",
       " (u'136639652273092899_2015_17_53',\n",
       "  u'136639652273370759_2015_17_53',\n",
       "  1444961868),\n",
       " (u'136639652273231459_2015_17_53',\n",
       "  u'136639652273343260_2015_17_53',\n",
       "  1444809104),\n",
       " (u'136639652273265689_2015_17_53',\n",
       "  u'136639652273333079_2015_17_53',\n",
       "  1445215747)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchaseEdge.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'136639652273091089_2015_17_53',\n",
       "  u'136639652273322821_2015_17_53',\n",
       "  'd',\n",
       "  1444608000),\n",
       " (u'136639652273079979_2015_17_53',\n",
       "  u'136639652273318351_2015_17_53',\n",
       "  'd',\n",
       "  1444780800),\n",
       " (u'136639652273092899_2015_17_53',\n",
       "  u'136639652273370759_2015_17_53',\n",
       "  'd',\n",
       "  1444953600),\n",
       " (u'136639652273231459_2015_17_53',\n",
       "  u'136639652273343260_2015_17_53',\n",
       "  'd',\n",
       "  1444780800),\n",
       " (u'136639652273265689_2015_17_53',\n",
       "  u'136639652273333079_2015_17_53',\n",
       "  'd',\n",
       "  1445212800)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dayly_rollup.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def purchase_by_hour(ts):\n",
    "    from collections import Counter\n",
    "    c = Counter(ts)\n",
    "    return c.keys(), c.values()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare User Property data for batch view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load and distribute pickle files into spark\n",
    "# create RDD\n",
    "pickled_userGender = sc.pickleFile(\"/Users/Alexander/DSCI6007-student/week2/\" + \n",
    "                                       \"Amazon_Lambda_Arch/master/user_property/gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickled_userLocation = sc.pickleFile(\"/Users/Alexander/DSCI6007-student/week2/\" + \n",
    "                                       \"Amazon_Lambda_Arch/master/user_property/location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickled_userName = sc.pickleFile(\"/Users/Alexander/DSCI6007-student/week2/\" + \n",
    "                                       \"Amazon_Lambda_Arch/master/user_property/user_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check data units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'dataunit': {u'user_property': {u'property': {u'gender': u'FEMALE'},\n",
       "   u'userID': {u'user_number': u'136639652273236830_2015_17_53'}}},\n",
       " u'pedigree': {u'true_as_of_secs': 1445119781}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_userGender.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'dataunit': {u'user_property': {u'property': {u'location': {u'city': u'Iron Ridge',\n",
       "     u'country': u'USA',\n",
       "     u'state': u'Wisconsin'}},\n",
       "   u'userID': {u'user_number': u'136639652273210078_2015_17_53'}}},\n",
       " u'pedigree': {u'true_as_of_secs': 1445023584}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_userLocation.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'dataunit': {u'user_property': {u'property': {u'user_name': {u'name': u'Dehlia Allin'}},\n",
       "   u'userID': {u'user_number': u'136639652272944609_2015_17_53'}}},\n",
       " u'pedigree': {u'true_as_of_secs': 1444861827}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_userName.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I haven't used this function for anything yet\n",
    "def hourly(datum):\n",
    "    item = datum['dataunit']['purchase_edge']['item_id']['item_number']\n",
    "    user = datum['dataunit']['purchase_edge']['userID']['user_number']\n",
    "    true_as_of_secs = datum['pedigree']['true_as_of_secs']\n",
    "    # return key, value\n",
    "    return user, item, 'h', true_as_of_secs - true_as_of_secs % granularity['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_gender(gender_datum):\n",
    "    \n",
    "    gender  = gender_datum['dataunit']['user_property']['property']['gender']\n",
    "    user_id = gender_datum['dataunit']['user_property']['userID']['user_number']\n",
    "    ts      = gender_datum['pedigree']['true_as_of_secs']\n",
    "    \n",
    "    return user_id, gender, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user_location(location_datum):\n",
    "    \n",
    "    city    = location_datum['dataunit']['user_property']['property']['location']['city']\n",
    "    state   = location_datum['dataunit']['user_property']['property']['location']['state']\n",
    "    country = location_datum['dataunit']['user_property']['property']['location']['country']\n",
    "    user_id = location_datum['dataunit']['user_property']['userID']['user_number']\n",
    "    ts      = location_datum['pedigree']['true_as_of_secs']\n",
    "    \n",
    "    return user_id, city,state,country, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_name(name_datum):\n",
    "    \n",
    "    name    = name_datum['dataunit']['user_property']['property']['user_name']['name']\n",
    "    user_id = name_datum['dataunit']['user_property']['userID']['user_number']\n",
    "    ts      = name_datum['pedigree']['true_as_of_secs']\n",
    "    \n",
    "#     return user_id, name, ts\n",
    "    return  user_id, name, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_gender = pickled_userGender.map(get_user_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_location = pickled_userLocation.map(get_user_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_name = pickled_userName.map(get_user_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check property data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'136639652273236830_2015_17_53', u'FEMALE', 1445119781),\n",
       " (u'136639652272939328_2015_17_53', u'FEMALE', 1445153678),\n",
       " (u'136639652273204820_2015_17_53', u'FEMALE', 1445095381),\n",
       " (u'136639652273225489_2015_17_53', u'FEMALE', 1445200616),\n",
       " (u'136639652273234009_2015_17_53', u'MALE', 1445266526)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_gender.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'136639652273210078_2015_17_53',\n",
       "  u'Iron Ridge',\n",
       "  u'Wisconsin',\n",
       "  u'USA',\n",
       "  1445023584),\n",
       " (u'136639652273228648_2015_17_53',\n",
       "  u'Weatogue',\n",
       "  u'Connecticut',\n",
       "  u'USA',\n",
       "  1445180207),\n",
       " (u'136639652273204559_2015_17_53',\n",
       "  u'Portage',\n",
       "  u'Pennsylvania',\n",
       "  u'USA',\n",
       "  1444821790),\n",
       " (u'136639652273239879_2015_17_53',\n",
       "  u'18251',\n",
       "  u'Pennsylvania',\n",
       "  u'USA',\n",
       "  1444787718),\n",
       " (u'136639652273235420_2015_17_53', u'Pelican', u'Alaska', u'USA', 1444985433)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_location.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize User Property Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_current_property(values):\n",
    "    '''scans property time stampts and selects the most current property '''\n",
    "    timestamp = -1\n",
    "    timestamps = dict()\n",
    "    \n",
    "    for prop in values:\n",
    "        timestamps[prop[timestamp]]=prop[:timestamp]\n",
    "    max_ts = max(timestamps.keys())\n",
    "    \n",
    "    if len(timestamps[max_ts]) == 1:\n",
    "        return (timestamps[max_ts][0],max_ts)\n",
    "    elif len(timestamps[max_ts]) == 2:\n",
    "        return (timestamps[max_ts][0],timestamps[max_ts][1],max_ts)\n",
    "    else:\n",
    "        return (timestamps[max_ts][0],timestamps[max_ts][1],timestamps[max_ts][2],max_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_names = user_name.map(lambda (user_id, name, ts): (user_id, (name, ts)))\\\n",
    "                            .groupByKey()\\\n",
    "                            .mapValues(lambda line: get_current_property(line))\\\n",
    "                            .map(lambda line: (line[0], line[1][0], line[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_locations = user_location.map(lambda ( user_id, city,state,country, ts): ( user_id, (city,state,country, ts)))\\\n",
    "                                  .groupByKey()\\\n",
    "                                  .mapValues(get_current_property)\\\n",
    "                                  .map(lambda line: (line[0], line[1][0],line[1][1],line[1][2],line[1][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_genders = user_gender.map(lambda ( user_id, gender, ts): ( user_id, (gender, ts)))\\\n",
    "                                .groupByKey()\\\n",
    "                                .mapValues(get_current_property)\\\n",
    "                                .map(lambda line: (line[0], line[1][0],line[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Item Propteries  for Batch View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickled_itemName = sc.pickleFile(\"/Users/Alexander/DSCI6007-student/week2/\" + \n",
    "                                 \"Amazon_Lambda_Arch/master/item_property/item_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_itemName(item_datum):\n",
    "    ID     = item_datum['dataunit']['item_property']['item_id']['item_number']\n",
    "    name    = item_datum['dataunit']['item_property']['property']['item_name']\n",
    "    ts      = item_datum['pedigree']['true_as_of_secs']\n",
    "    return ID, name, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_name = pickled_itemName.map(get_itemName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'136639652273340198_2015_17_53', u'garmin-nuvi-660', 1445245982)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_name.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Review Edge  for Batch View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickled_reviewEdge = sc.pickleFile(\"/Users/Alexander/DSCI6007-student/week2/\" + \n",
    "                                 \"Amazon_Lambda_Arch/master/review_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_review_rating(review_datum):\n",
    "    user_id = review_datum['dataunit']['review_edge']['userID']['user_number']\n",
    "    item_id = review_datum['dataunit']['review_edge']['item_id']['item_number']\n",
    "    rating  = review_datum['dataunit']['review_edge']['rating']\n",
    "    review  = review_datum['dataunit']['review_edge']['review']\n",
    "    ts      = review_datum['pedigree']['true_as_of_secs']\n",
    "    return user_id, item_id, rating, ts, review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviewEdge = pickled_reviewEdge.map(get_review_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'136639652273231459_2015_17_53',\n",
       "  u'136639652273343260_2015_17_53',\n",
       "  5,\n",
       "  1445198294,\n",
       "  u'null')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewEdge.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step: Create batch views with SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.context.HiveContext object at 0x10dfff0d0>\n"
     ]
    }
   ],
   "source": [
    "# create sql context\n",
    "sqlContext = pyspark.HiveContext(sc)\n",
    "print sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed gvmagic.py. To use it, type:\n",
      "  %load_ext gvmagic\n"
     ]
    }
   ],
   "source": [
    "%install_ext https://raw.github.com/cjdrake/ipython-magic/master/gvmagic.py\n",
    "%load_ext gvmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create schemas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_gender = StructType( [\n",
    "    StructField('user_id',StringType(),True),\n",
    "    StructField('gender',StringType(),True),\n",
    "    StructField('timestamp',IntegerType(),True),] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_location = StructType( [\n",
    "    StructField('user_id',StringType(),True),\n",
    "    StructField('city',StringType(),True),\n",
    "    StructField('state',StringType(),True),\n",
    "    StructField('country',StringType(),True),\n",
    "    StructField('timestamp',IntegerType(),True),] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_name = StructType( [\n",
    "    StructField('user_id',StringType(),True),\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField('timestamp',IntegerType(),True),] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_review = StructType( [\n",
    "    StructField('user_id',StringType(),True),\n",
    "    StructField('item_id',StringType(),True),\n",
    "    StructField('rating',IntegerType(),True),\n",
    "    StructField('timestamp',IntegerType(),True),\n",
    "    StructField('review',StringType(),True)\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_item_name = StructType( [\n",
    "    StructField('item_id',StringType(),True),\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField('timestamp',IntegerType(),True)\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_purchase = StructType( [\n",
    "    StructField('user_id',StringType(),True),\n",
    "    StructField('item_id',StringType(),True),\n",
    "    StructField('timestamp',IntegerType(),True)\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema_dayly = StructType( [\n",
    "    StructField('user_id',StringType(),True),\n",
    "    StructField('item_id',StringType(),True),\n",
    "    StructField('timestamp',IntegerType(),True)\n",
    "] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user_id, gender, ts\n",
    "gender = sqlContext.createDataFrame(normalized_genders, schema_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user_id, city,state,country, ts\n",
    "location = sqlContext.createDataFrame(normalized_locations, schema_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ID, name, ts\n",
    "userName = sqlContext.createDataFrame(normalized_names, schema_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user_id, item_id, rating, ts, review\n",
    "review = sqlContext.createDataFrame(reviewEdge, schema_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ID, name, ts\n",
    "itemName = sqlContext.createDataFrame(item_name, schema_item_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user, item,true_as_of_secs \n",
    "purchase = sqlContext.createDataFrame(purchaseEdge, schema_purchase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register tables with SparkSQL -- These are Batches of the Master Data set  !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender.registerTempTable(\"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location.registerTempTable(\"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userName.registerTempTable(\"user_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review.registerTempTable(\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemName.registerTempTable(\"item_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase.registerTempTable(\"purchase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Batch Views with SparkSQL Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch View DAG for Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"345pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 345.46 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-472 341.459,-472 341.459,4 -4,4\"/>\n",
       "<!-- gender -->\n",
       "<g id=\"node1\" class=\"node\"><title>gender</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"111.443,-396 0.185417,-396 0.185417,-360 111.443,-360 111.443,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.814\" y=\"-380.8\" font-family=\"Times,serif\" font-size=\"14.00\">gender:</text>\n",
       "<text text-anchor=\"middle\" x=\"55.814\" y=\"-366.8\" font-family=\"Times,serif\" font-size=\"14.00\">[user_id, gender]</text>\n",
       "</g>\n",
       "<!-- female -->\n",
       "<g id=\"node4\" class=\"node\"><title>female</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"105.091,-324 6.53735,-324 6.53735,-288 105.091,-288 105.091,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.814\" y=\"-308.8\" font-family=\"Times,serif\" font-size=\"14.00\">aggragate:</text>\n",
       "<text text-anchor=\"middle\" x=\"55.814\" y=\"-294.8\" font-family=\"Times,serif\" font-size=\"14.00\">percent female</text>\n",
       "</g>\n",
       "<!-- gender&#45;&gt;female -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>gender&#45;&gt;female</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M55.814,-359.697C55.814,-351.983 55.814,-342.712 55.814,-334.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"59.3141,-334.104 55.814,-324.104 52.3141,-334.104 59.3141,-334.104\"/>\n",
       "</g>\n",
       "<!-- location -->\n",
       "<g id=\"node2\" class=\"node\"><title>location</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"222.508,-324 123.12,-324 123.12,-288 222.508,-288 222.508,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-308.8\" font-family=\"Times,serif\" font-size=\"14.00\">location:</text>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-294.8\" font-family=\"Times,serif\" font-size=\"14.00\">[user_id, state]</text>\n",
       "</g>\n",
       "<!-- join -->\n",
       "<g id=\"node7\" class=\"node\"><title>join</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"199.814,-252 145.814,-252 145.814,-216 199.814,-216 199.814,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\">join</text>\n",
       "</g>\n",
       "<!-- location&#45;&gt;join -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>location&#45;&gt;join</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.814,-287.697C172.814,-279.983 172.814,-270.712 172.814,-262.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.314,-262.104 172.814,-252.104 169.314,-262.104 176.314,-262.104\"/>\n",
       "</g>\n",
       "<!-- purchase -->\n",
       "<g id=\"node3\" class=\"node\"><title>purchase</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"337.604,-468 214.024,-468 214.024,-432 337.604,-432 337.604,-468\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.814\" y=\"-452.8\" font-family=\"Times,serif\" font-size=\"14.00\">purchase:</text>\n",
       "<text text-anchor=\"middle\" x=\"275.814\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\">[user_id, purchase]</text>\n",
       "</g>\n",
       "<!-- count1 -->\n",
       "<g id=\"node5\" class=\"node\"><title>count1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"324.859,-396 226.769,-396 226.769,-360 324.859,-360 324.859,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.814\" y=\"-380.8\" font-family=\"Times,serif\" font-size=\"14.00\">count:</text>\n",
       "<text text-anchor=\"middle\" x=\"275.814\" y=\"-366.8\" font-family=\"Times,serif\" font-size=\"14.00\">distinct buyers</text>\n",
       "</g>\n",
       "<!-- purchase&#45;&gt;count1 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>purchase&#45;&gt;count1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M275.814,-431.697C275.814,-423.983 275.814,-414.712 275.814,-406.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"279.314,-406.104 275.814,-396.104 272.314,-406.104 279.314,-406.104\"/>\n",
       "</g>\n",
       "<!-- female&#45;&gt;join -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>female&#45;&gt;join</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.4354,-287.876C100.19,-278.45 119.896,-266.66 136.7,-256.606\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.909,-259.363 145.694,-251.226 135.315,-253.356 138.909,-259.363\"/>\n",
       "</g>\n",
       "<!-- count2 -->\n",
       "<g id=\"node6\" class=\"node\"><title>count2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"311.514,-324 240.113,-324 240.113,-288 311.514,-288 311.514,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.814\" y=\"-308.8\" font-family=\"Times,serif\" font-size=\"14.00\">count:</text>\n",
       "<text text-anchor=\"middle\" x=\"275.814\" y=\"-294.8\" font-family=\"Times,serif\" font-size=\"14.00\">purchases</text>\n",
       "</g>\n",
       "<!-- count1&#45;&gt;count2 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>count1&#45;&gt;count2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M275.814,-359.697C275.814,-351.983 275.814,-342.712 275.814,-334.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"279.314,-334.104 275.814,-324.104 272.314,-334.104 279.314,-334.104\"/>\n",
       "</g>\n",
       "<!-- count2&#45;&gt;join -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>count2&#45;&gt;join</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.617,-287.876C237.399,-278.893 221.022,-267.763 206.707,-258.034\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208.346,-254.916 198.107,-252.19 204.411,-260.705 208.346,-254.916\"/>\n",
       "</g>\n",
       "<!-- groupby -->\n",
       "<g id=\"node8\" class=\"node\"><title>groupby</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"205.867,-180 139.761,-180 139.761,-144 205.867,-144 205.867,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-164.8\" font-family=\"Times,serif\" font-size=\"14.00\">groupby:</text>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">state</text>\n",
       "</g>\n",
       "<!-- join&#45;&gt;groupby -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>join&#45;&gt;groupby</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.814,-215.697C172.814,-207.983 172.814,-198.712 172.814,-190.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.314,-190.104 172.814,-180.104 169.314,-190.104 176.314,-190.104\"/>\n",
       "</g>\n",
       "<!-- orderby -->\n",
       "<g id=\"node9\" class=\"node\"><title>orderby</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"204.743,-108 140.885,-108 140.885,-72 204.743,-72 204.743,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">orderby:</text>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\">state</text>\n",
       "</g>\n",
       "<!-- groupby&#45;&gt;orderby -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>groupby&#45;&gt;orderby</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.814,-143.697C172.814,-135.983 172.814,-126.712 172.814,-118.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.314,-118.104 172.814,-108.104 169.314,-118.104 176.314,-118.104\"/>\n",
       "</g>\n",
       "<!-- Output -->\n",
       "<g id=\"node10\" class=\"node\"><title>Output</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"298.094,-36 47.5336,-36 47.5336,-0 298.094,-0 298.094,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Output:</text>\n",
       "<text text-anchor=\"middle\" x=\"172.814\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">[state, percent_female, buyers, purchases]</text>\n",
       "</g>\n",
       "<!-- orderby&#45;&gt;Output -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>orderby&#45;&gt;Output</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.814,-71.6966C172.814,-63.9827 172.814,-54.7125 172.814,-46.1124\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.314,-46.1043 172.814,-36.1043 169.314,-46.1044 176.314,-46.1043\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%dot digraph {  \n",
    "    # rankdir=LR;\n",
    "    node [shape=box]\n",
    "    \n",
    "    gender     [label = \"gender:\\n[user_id, gender]\"]\n",
    "    location   [label = \"location:\\n[user_id, state]\"]\n",
    "    purchase   [label = \"purchase:\\n[user_id, purchase]\"]\n",
    "    female     [label = \"aggragate:\\npercent female\"]\n",
    "    count1     [label = \"count:\\ndistinct buyers\"]\n",
    "    count2     [label = \"count:\\npurchases\"]\n",
    "    join       [label = \"join\"]\n",
    "    groupby    [label = \"groupby:\\nstate\"]\n",
    "    orderby    [label = \"orderby:\\nstate\"]\n",
    "    Output     [label = \"Output:\\n[state, percent_female, buyers, purchases]\"]\n",
    "    \n",
    "    gender -> female;\n",
    "    female -> join;\n",
    "    location -> join;\n",
    "    purchase -> count1;\n",
    "    count1 -> count2;\n",
    "    count2 -> join;\n",
    "    join -> groupby;\n",
    "    groupby -> orderby;\n",
    "    orderby -> Output;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: What are the ratings and reviews of purchased items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_view_reviews = \\\n",
    "sqlContext.sql(\"\"\"SELECT item_name.name AS ItemName, review.rating AS rating, review.review \n",
    "                  FROM review\n",
    "                  LEFT JOIN item_name\n",
    "                  ON review.item_id = item_name.item_id\n",
    "                  ORDER BY ItemName\n",
    "                  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: From where in the US  are users making purchases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_view_purchase_info = \\\n",
    "sqlContext.sql(\"\"\"SELECT location.country,location.state, location.city, \n",
    "                  COUNT (distinct location.user_id) AS users,\n",
    "                  COUNT(distinct purchase.item_id) AS purchases\n",
    "                  FROM location\n",
    "                  LEFT JOIN purchase\n",
    "                  ON location.user_id = purchase.user_id\n",
    "                  GROUP by location.country, location.state, location.city\n",
    "                  ORDER BY location.state\n",
    "                  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: What are the user demographics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_view_demographics = \\\n",
    "sqlContext.sql(\"\"\"SELECT user_name.name, gender.gender, location.city,location.state,location.country\n",
    "                  FROM user_name\n",
    "                  FULL OUTER JOIN gender\n",
    "                  ON user_name.user_id = gender.user_id\n",
    "                  FULL OUTER JOIN location\n",
    "                  ON user_name.user_id = location.user_id\n",
    "                  ORDER BY user_name.name\n",
    "                  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save batch views to parquet\n",
    "    We write batch views to parquet because parqeut has the fastest query time\n",
    "    compared .txt, .csv, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_view_purchase_info.write.parquet(\"~/DSCI6007-student/week2/Amazon_Lambda_Arch/batch_views/purchase_info\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_view_demographics.write.parquet(\"~/DSCI6007-student/week2/Amazon_Lambda_Arch/batch_views/demographics\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_view_reviews.write.parquet(\"~/DSCI6007-student/week2/Amazon_Lambda_Arch/batch_views/reivews\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving Layer\n",
    "    Here, we will upload our batch views and run adhoc queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase_view = sqlContext.read.parquet(\"~/DSCI6007-student/week2/Amazon_Lambda_Arch/batch_views/purchase_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demographics_view = sqlContext.read.parquet(\"~/DSCI6007-student/week2/Amazon_Lambda_Arch/batch_views/demographics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase_view.registerTempTable('purchase_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demographics_view.registerTempTable('demo_view')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query batch views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------+-----+---------+\n",
      "|country|   state|       city|users|purchases|\n",
      "+-------+--------+-----------+-----+---------+\n",
      "|    USA|Missouri|      65548|    1|        2|\n",
      "|    USA|Missouri|   La Monte|    1|        1|\n",
      "|    USA|Missouri|      63650|    1|        3|\n",
      "|    USA|Missouri|      64499|    1|        0|\n",
      "|    USA|Missouri|Pilot Grove|    1|        4|\n",
      "|    USA|Missouri|      65324|    1|        2|\n",
      "|    USA|Missouri|    Advance|    1|        1|\n",
      "|    USA|Missouri|  Weaubleau|    1|        0|\n",
      "|    USA|Missouri| Monticello|    1|        2|\n",
      "|    USA|Missouri|      63557|    1|        1|\n",
      "|    USA|Missouri|    Raymore|    1|        2|\n",
      "|    USA|Missouri|      64788|    1|        0|\n",
      "|    USA|Missouri|   Leadwood|    1|        3|\n",
      "|    USA|Missouri|      64726|    1|        4|\n",
      "|    USA|Missouri|      63060|    1|        2|\n",
      "|    USA|Missouri|      65459|    1|        2|\n",
      "|    USA|Missouri|      63111|    1|        2|\n",
      "|    USA|Missouri|      65233|    1|        0|\n",
      "|    USA|Missouri|      64505|    1|        1|\n",
      "|    USA|Missouri|      65239|    1|        2|\n",
      "+-------+--------+-----------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"SELECT *\n",
    "                  FROM purchase_view\n",
    "                  \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: How many purchases are made in each state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|         state|purchases|\n",
      "+--------------+---------+\n",
      "|    California|       63|\n",
      "|         Texas|       62|\n",
      "|      New York|       46|\n",
      "|          Ohio|       41|\n",
      "|  Pennsylvania|       39|\n",
      "|       Georgia|       38|\n",
      "|      Missouri|       36|\n",
      "|      Illinois|       35|\n",
      "|       Florida|       33|\n",
      "|North Carolina|       31|\n",
      "|     Minnesota|       31|\n",
      "|          Iowa|       30|\n",
      "|     Wisconsin|       27|\n",
      "|      Michigan|       26|\n",
      "|      Virginia|       26|\n",
      "|     Tennessee|       20|\n",
      "|    Washington|       19|\n",
      "|        Kansas|       19|\n",
      "| West Virginia|       19|\n",
      "|      Kentucky|       18|\n",
      "+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SUGGESTION: filter non-state names out of state data\n",
    "#             change state initials into full names (there should be a table I can download)\n",
    "sqlContext.sql(\"\"\"SELECT state, \n",
    "                  COUNT(purchases) AS purchases\n",
    "                  FROM purchase_view\n",
    "                  GROUP BY state\n",
    "                  ORDER BY purchases\n",
    "                  DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+-------------+--------------+-------+\n",
      "|             name|gender|         city|         state|country|\n",
      "+-----------------+------+-------------+--------------+-------+\n",
      "|   Michelina Tana|  MALE|   Mount Hope|    California|    USA|\n",
      "|      Micki Minta|  MALE|       Cheraw|South Carolina|    USA|\n",
      "|  Milissent Muire|FEMALE|     Bellevue|      Illinois|    USA|\n",
      "|      Milt Fionna|  MALE|Cape Porpoise|         Maine|    USA|\n",
      "|    Minerva Frank|  MALE| Meadow Vista|    California|    USA|\n",
      "|       Thorn Tera|FEMALE|        98941|    Washington|    USA|\n",
      "|Thorstein Hilarie|  MALE|        98168|    Washington|    USA|\n",
      "| Thorsten Thedric|FEMALE|        85296|       Arizona|    USA|\n",
      "|    Thorvald Maxi|FEMALE|    Melbourne|          Iowa|    USA|\n",
      "|     Tiana Chicky|  MALE|        92075|    California|    USA|\n",
      "|      Easton Ware|FEMALE|        70810|     Louisiana|    USA|\n",
      "|       Eben Alana|  MALE|        78237|         Texas|    USA|\n",
      "|        Eben Doro|  MALE|        58415|  North Dakota|    USA|\n",
      "|     Ebonee Verge|  MALE|        55946|     Minnesota|    USA|\n",
      "|  Ebony Brunhilde|  null|        78251|         Texas|    USA|\n",
      "|         Abe Katy|  MALE|    Glen Cove|      New York|    USA|\n",
      "|    Abra Theodore|FEMALE|        33815|       Florida|    USA|\n",
      "|      Adina Josey|  MALE|        78879|         Texas|    USA|\n",
      "|   Aditya Shelden|  MALE|  Lyon County|        Kansas|    USA|\n",
      "|     Adora Krista|FEMALE|        29161|South Carolina|    USA|\n",
      "+-----------------+------+-------------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT *  FROM demo_view\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: What is the personal information of users that live in California?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+-------------+\n",
      "|               name|gender|         city|\n",
      "+-------------------+------+-------------+\n",
      "|    Alice Ekaterina|FEMALE|      Daggett|\n",
      "|      Alisun Michel|  MALE|   Sun Valley|\n",
      "|       Amadeus Cloe|FEMALE|        90731|\n",
      "|    Amalita Pamella|  MALE| Bay Terraces|\n",
      "|        Andrei Fina|FEMALE|        93241|\n",
      "|       Ardelle Shea|FEMALE| Chinese Camp|\n",
      "|        Arne Tracee|  MALE|        93304|\n",
      "|     Brietta Jaclin|FEMALE|        95721|\n",
      "|       Chicky Nelly|FEMALE|        92365|\n",
      "|    Corrie Felicdad|  MALE|        95673|\n",
      "|      Delinda Hyatt|  MALE|        94609|\n",
      "|        Dorey Shana|FEMALE|      Soledad|\n",
      "|     Dorie Madeline|FEMALE|    King City|\n",
      "|         Edithe Koo|FEMALE|        93609|\n",
      "|Enrichetta Chloette|FEMALE|   Ben Lomond|\n",
      "|     Felipe Enrique|FEMALE|        96021|\n",
      "|       Forster Dacy|  MALE|        92211|\n",
      "|     Forster Lesley|  MALE|        93063|\n",
      "|        Gale Lianna|  MALE|   Cottonwood|\n",
      "|    Godiva Bridgett|  MALE|Magnolia Park|\n",
      "+-------------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"SELECT name, gender,city  \n",
    "                  FROM demo_view\n",
    "                  WHERE state = 'California'\n",
    "                  ORDER BY name\n",
    "                  ASC\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
