{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Create  \"Pivot Table\" and Save to File\n",
    "    COPY (select costumerhash,\n",
    "         array_agg(ROW(productkey,unit_sum))\n",
    "    AS units_list\n",
    "    FROM(\n",
    "          SELECT costumerhash, productkey,\n",
    "              SUM(units) AS unit_sum\n",
    "              FROM purchases\n",
    "              GROUP BY costumerhash, productkey\n",
    "      ) AS row\n",
    "    GROUP BY costumerhash\n",
    "    ORDER BY costumerhash)\n",
    "\n",
    "    TO '/Users/Alexander/pivot_tabe.csv' \n",
    "    (FORMAT CSV, DELIMITER ',');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    00000F7264C27BA6FEA0C837ED6AA0AA | {\"(202463,1)\",\"(202922,1)\",\"(205598,1)\",\"(214365,1)\",\"(214573,1)}\n",
    "    0000219E4B37D2504FB6B8C28E24A2D4 | {\"(25604,1)\"}\n",
    "    000051F32D02C8A53B43A686969676E6 | {\"(91836,1)\",\"(107120,1)\",\"(107193,1)\",\"(109231,1)\",\"(111359,1)}\n",
    "    00005C2D819C584E32298F8729C4B1D7 | {\"(22374,3)\",\"(256047,7)\"}\n",
    "    00006C661B0C80EF519BA561E321D100 | {\"(363343,2)\"}\n",
    "    0000702EE4CEFDB1E7F89084E50D3C85 | {\"(362634,1)\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Basic Exploration\n",
    "\n",
    "1. What are the tables in our database? Run `\\d` to find out.\n",
    "\n",
    "\n",
    "    readychef-# \\d\n",
    "               List of relations\n",
    "     Schema |   Name    | Type  |   Owner   \n",
    "    --------+-----------+-------+-----------\n",
    "     public | events    | table | Alexander\n",
    "     public | meals     | table | Alexander\n",
    "     public | referrals | table | Alexander\n",
    "     public | users     | table | Alexander\n",
    "     public | visits    | table | Alexander\n",
    "    (5 rows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. What columns does each table have? Run `\\d tablename` to find out.\n",
    "\n",
    "\n",
    "    readychef-# \\d events\n",
    "              Table \"public.events\"\n",
    "     Column  |       Type        | Modifiers \n",
    "    ---------+-------------------+-----------\n",
    "     dt      | date              | \n",
    "     userid  | integer           | \n",
    "     meal_id | integer           | \n",
    "     event   | character varying | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select statements\n",
    "===================\n",
    "\n",
    "1) To get an understanding of the data, run a [SELECT](http://www.postgresqltutorial.com/postgresql-select/) statement on each table. Keep all the columns and limit the number of rows to 10.\n",
    "\n",
    "        SELECT * \n",
    "        FROM events \n",
    "        LIMIT 10;\n",
    "             dt     | userid | meal_id | event  \n",
    "        ------------+--------+---------+--------\n",
    "         2013-01-01 |      3 |      18 | bought\n",
    "         2013-01-01 |      7 |       1 | like\n",
    "         2013-01-01 |     10 |      29 | bought\n",
    "         2013-01-01 |     11 |      19 | share\n",
    "         2013-01-01 |     15 |      33 | like\n",
    "         2013-01-01 |     18 |       4 | share\n",
    "         2013-01-01 |     18 |      40 | bought\n",
    "         2013-01-01 |     21 |      10 | share\n",
    "         2013-01-01 |     21 |       4 | like\n",
    "         2013-01-01 |     22 |      23 | bought\n",
    "        (10 rows)\n",
    "    \n",
    "\n",
    "2) Write a `SELECT` statement that would get just the userids.\n",
    "\n",
    "        SELECT userid from visits;\n",
    "\n",
    "\n",
    "3) Maybe you're just interested in what the campaign ids are. Use 'SELECT DISTINCT' to figure out all the possible values of that column.\n",
    "\n",
    "\n",
    "        SELECT campaign_id FROM users;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where Clauses / Filtering\n",
    "========================================\n",
    "\n",
    "\n",
    "1) Using the `WHERE` clause, write a new `SELECT` statement that returns all rows where `Campaign_ID` is equal to `FB`.\n",
    "\n",
    "        SELECT campaign_id \n",
    "        FROM users \n",
    "        WHERE campaign_id = 'FB';\n",
    "\n",
    "    readychef=# select campaign_id from users where campaign_id = 'FB' limit 10;\n",
    "     campaign_id \n",
    "    -------------\n",
    "     FB\n",
    "     FB\n",
    "     FB\n",
    "     FB\n",
    "     FB\n",
    "     FB\n",
    "     FB\n",
    "     FB\n",
    "     FB\n",
    "     FB\n",
    "    (10 rows)\n",
    "\n",
    "\n",
    "2) We don't need the campaign id in the result since they are all the same, so only include the other two columns.\n",
    "\n",
    "    SELECT userid, dt\n",
    "    FROM users\n",
    "    WHERE campaign_id = 'FB';\n",
    "\n",
    "    readychef=# select userid, dt  from users where campaign_id = 'FB' limit 10;\n",
    "     userid |     dt     \n",
    "    --------+------------\n",
    "          3 | 2013-01-01\n",
    "          4 | 2013-01-01\n",
    "          5 | 2013-01-01\n",
    "          6 | 2013-01-01\n",
    "          8 | 2013-01-01\n",
    "          9 | 2013-01-01\n",
    "         12 | 2013-01-01\n",
    "         17 | 2013-01-01\n",
    "         19 | 2013-01-01\n",
    "         24 | 2013-01-01\n",
    "    (10 rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Aggregation Functions\n",
    "=======================\n",
    "\n",
    "1) Write a query to get the count of just the users who came from Facebook.\n",
    "\n",
    "        SELECT COUNT(*) \n",
    "        FROM users \n",
    "        WHERE campaign_id = 'FB';\n",
    "\n",
    "2) Now, count the number of users coming from each service. Here you'll have to group by the column you're selecting with a [GROUP BY](http://www.postgresql.org/docs/8.0/static/sql-select.html#SQL-GROUPBY) clause.\n",
    "\n",
    "        SELECT campaign_id, COUNT(*) \n",
    "        From users \n",
    "        GROUP BY campaign_id;\n",
    "        \n",
    "         campaign_id | count \n",
    "        -------------+-------\n",
    "         RE          |  1724\n",
    "         FB          |  4384\n",
    "         TW          |  3764\n",
    "         PI          |  1176\n",
    "        (4 rows)\n",
    "\n",
    "3) Use `COUNT (DISTINCT columnname)` to get the number of unique dates that appear in the `users` table.\n",
    "\n",
    "\n",
    "       SELECT campaign_id, \n",
    "       COUNT(distinct dt) \n",
    "       FROM users \n",
    "       GROUP BY campaign_id;\n",
    "       \n",
    "         campaign_id | count \n",
    "        -------------+-------\n",
    "         FB          |   331\n",
    "         PI          |   251\n",
    "         RE          |   285\n",
    "         TW          |   328\n",
    "        (4 rows)\n",
    "\n",
    "\n",
    "4) There's also `MAX` and `MIN` functions, which do what you might expect. Write a query to get the first and last registration date from the `users` table.\n",
    "\n",
    "        \n",
    "        SELECT MAX(dt), \n",
    "               MIN(dt)\n",
    "        From users;\n",
    "            max     |    min     \n",
    "        ------------+------------\n",
    "         2013-12-31 | 2013-01-01\n",
    "        (1 row)\n",
    "\n",
    "5) Calculate the mean price for a meal (from the `meals` table).\n",
    "\n",
    "        SELECT AVG(price)\n",
    "        FROM meals;\n",
    "        \n",
    "                 avg         \n",
    "        ---------------------\n",
    "         10.6522829904666332\n",
    "        (1 row)\n",
    "\n",
    "\n",
    "6) Now get the average price, the min price and the max price for each meal type.\n",
    "\n",
    "\n",
    "        SELECT type, AVG(price),MIN(price),MAX(price) \n",
    "        FROM meals \n",
    "        GROUP BY type;\n",
    "        \n",
    "        \n",
    "        type    |         avg         | min | max \n",
    "    ------------+---------------------+-----+-----\n",
    "     mexican    |  9.6975945017182131 |   6 |  13\n",
    "     french     | 11.5420000000000000 |   7 |  16\n",
    "     japanese   |  9.3804878048780488 |   6 |  13\n",
    "     italian    | 11.2926136363636364 |   7 |  16\n",
    "     chinese    |  9.5187165775401070 |   6 |  13\n",
    "     vietnamese |  9.2830188679245283 |   6 |  13\n",
    "    (6 rows)\n",
    "\n",
    "7)  Alias all the above columns\n",
    "\n",
    "        SELECT type, AVG(price) as avg_price , MIN(price) as min_price, MAX(price) as max_price \n",
    "        FROM meals  \n",
    "        GROUP BY type;\n",
    "            type    |      avg_price      | min_price | max_price \n",
    "        ------------+---------------------+-----------+-----------\n",
    "         mexican    |  9.6975945017182131 |         6 |        13\n",
    "         french     | 11.5420000000000000 |         7 |        16\n",
    "         japanese   |  9.3804878048780488 |         6 |        13\n",
    "         italian    | 11.2926136363636364 |         7 |        16\n",
    "         chinese    |  9.5187165775401070 |         6 |        13\n",
    "         vietnamese |  9.2830188679245283 |         6 |        13\n",
    "        (6 rows)\n",
    "        \n",
    "        \n",
    "8) Add a `WHERE` clause to the above query to consider only meals in the first quarter of 2013 (month<=3 and year=2013)\n",
    "\n",
    "\n",
    "        SELECT type , AVG(price), MIN(price), MAX(price) \n",
    "        FROM meals \n",
    "        WHERE date_part('month',  dt) <= 3 AND date_part('year',  dt)= 2013 \n",
    "        GROUP BY type;\n",
    "\n",
    "\n",
    "            type    |         avg         | min | max \n",
    "        ------------+---------------------+-----+-----\n",
    "         mexican    |  9.6951219512195122 |   6 |  13\n",
    "         french     | 11.7522123893805310 |   7 |  16\n",
    "         japanese   |  9.6521739130434783 |   6 |  13\n",
    "         vietnamese |  9.3750000000000000 |   6 |  13\n",
    "         italian    | 11.0877192982456140 |   7 |  16\n",
    "         chinese    |  9.7727272727272727 |   6 |  13\n",
    "        (6 rows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "9) Modify the above query so that we get the aggregate values for each month and type\n",
    "\n",
    "        SELCT date_part('month',  dt)  ,   type , avg( price), min(price), max(price) \n",
    "        FROM meals \n",
    "        WHERE date_part('month',  dt) <= 3 AND date_part('year',  dt)= 2013 \n",
    "        GROUP BY date_part('month',  dt),  type;\n",
    "\n",
    "\n",
    "\n",
    "     date_part |    type    |         avg         | min | max \n",
    "    -----------+------------+---------------------+-----+-----\n",
    "             1 | mexican    | 10.3823529411764706 |   6 |  13\n",
    "             2 | japanese   |  9.9166666666666667 |   6 |  13\n",
    "             3 | mexican    |  9.6250000000000000 |   6 |  13\n",
    "             3 | french     | 12.5238095238095238 |   8 |  16\n",
    "             2 | vietnamese |  9.6000000000000000 |   7 |  13\n",
    "             1 | chinese    | 11.2307692307692308 |   8 |  13\n",
    "             2 | italian    | 11.2666666666666667 |   7 |  16\n",
    "             3 | chinese    |  9.2500000000000000 |   6 |  13\n",
    "             2 | french     | 10.8387096774193548 |   7 |  16\n",
    "             2 | mexican    |  8.7916666666666667 |   6 |  13\n",
    "             3 | japanese   |  9.5238095238095238 |   6 |  13\n",
    "             1 | japanese   |  9.6153846153846154 |   6 |  13\n",
    "             1 | italian    | 10.8030303030303030 |   7 |  16\n",
    "             2 | chinese    |  9.0666666666666667 |   6 |  13\n",
    "             3 | italian    | 11.2666666666666667 |   7 |  16\n",
    "             3 | vietnamese |  8.8235294117647059 |   6 |  13\n",
    "             1 | vietnamese | 10.8000000000000000 |   6 |  13\n",
    "             1 | french     | 11.6500000000000000 |   7 |  16\n",
    "    (18 rows)\n",
    "\n",
    "\n",
    "\n",
    "10) From the `events` table, write a query that gets the total number of buys, likes and shares for each meal id. To avoid having to do this as three separate queries you can do the count of the number of buys like this: `SUM(CASE WHEN event='bought' THEN 1 ELSE 0 END)`.\n",
    "\n",
    "\n",
    "            SELECT sum( case when event = 'bought' then 1 else 0 end )\n",
    "            AS bought, \n",
    "            sum( case when event = 'like' then 1 else 0 end )AS like, \n",
    "            sum( case when event = 'share' then 1 else 0 end )AS share \n",
    "            FROM events;\n",
    "\n",
    "         bought |  like  | share  \n",
    "        --------+--------+--------\n",
    "         128538 | 249994 | 257708\n",
    "        (1 row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sorting\n",
    "==========================================\n",
    "\n",
    "1) Let's start with a query which gets the average price for each type. It will be helfpul to alias the average price column as 'avg_price'.\n",
    "\n",
    "\n",
    "        SELECT type, AVG(price) AS avg_price\n",
    "        FROM meals \n",
    "        GROUP BY type;\n",
    "        \n",
    "            type    |      avg_price      \n",
    "        ------------+---------------------\n",
    "         mexican    |  9.6975945017182131\n",
    "         french     | 11.5420000000000000\n",
    "         japanese   |  9.3804878048780488\n",
    "         italian    | 11.2926136363636364\n",
    "         chinese    |  9.5187165775401070\n",
    "         vietnamese |  9.2830188679245283\n",
    "        (6 rows)\n",
    "\n",
    "\n",
    "2) To make it easier to read, sort the results by the `type` column. You can do this with an [ORDER BY](http://www.postgresqltutorial.com/postgresql-order-by/) clause.\n",
    "\n",
    "        SELECT type, AVG(price) AS avg_price \n",
    "        FROM meals GROUP BY type  \n",
    "        ORDER BY type ASC;\n",
    "        \n",
    "            type    |      avg_price      \n",
    "        ------------+---------------------\n",
    "         chinese    |  9.5187165775401070\n",
    "         french     | 11.5420000000000000\n",
    "         italian    | 11.2926136363636364\n",
    "         japanese   |  9.3804878048780488\n",
    "         mexican    |  9.6975945017182131\n",
    "         vietnamese |  9.2830188679245283\n",
    "        (6 rows)\n",
    "\n",
    "\n",
    "\n",
    "3) Now return the same table again, except this time order by the price in descending order (add the `DESC` keyword).\n",
    "\n",
    "\n",
    "        SELECT type, AVG(price) AS avg_price \n",
    "        FROM meals GROUP BY type  \n",
    "        ORDER BY avg_price desc;\n",
    "\n",
    "\n",
    "            type    |      avg_price      \n",
    "        ------------+---------------------\n",
    "         french     | 11.5420000000000000\n",
    "         italian    | 11.2926136363636364\n",
    "         mexican    |  9.6975945017182131\n",
    "         chinese    |  9.5187165775401070\n",
    "         japanese   |  9.3804878048780488\n",
    "         vietnamese |  9.2830188679245283\n",
    "        (6 rows)\n",
    "\n",
    "\n",
    "4) Sometimes we want to sort by two columns. Write a query to get all the meals, but sort by the type and then by the price. You should have an order by clause that looks something like this: `ORDER BY col1, col2`.\n",
    "\n",
    "        SELECT type, AVG(price) AS avg_price \n",
    "        FROM meals \n",
    "        GROUP BY type  \n",
    "        ORDER BY type,  avg_price;\n",
    "\n",
    "            type    |      avg_price      \n",
    "        ------------+---------------------\n",
    "         chinese    |  9.5187165775401070\n",
    "         french     | 11.5420000000000000\n",
    "         italian    | 11.2926136363636364\n",
    "         japanese   |  9.3804878048780488\n",
    "         mexican    |  9.6975945017182131\n",
    "         vietnamese |  9.2830188679245283\n",
    "\n",
    "\n",
    "\n",
    "5) For shorthand, people sometimes use numbers to refer to the columns in their order by or group by clauses. The numbers refer to the order they are in the select statement. For instance `SELECT type, dt FROM meals ORDER BY 1;` would order the resutls by the `type` column.\n",
    "\n",
    "\n",
    "        SELECT type, AVG(price) AS avg_price \n",
    "        FROM meals \n",
    "        GROUP BY 1  \n",
    "        ORDER BY 1,  2;\n",
    "\n",
    "            type    |      avg_price      \n",
    "        ------------+---------------------\n",
    "         chinese    |  9.5187165775401070\n",
    "         french     | 11.5420000000000000\n",
    "         italian    | 11.2926136363636364\n",
    "         japanese   |  9.3804878048780488\n",
    "         mexican    |  9.6975945017182131\n",
    "         vietnamese |  9.2830188679245283\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Joins\n",
    "=========================\n",
    "\n",
    "\n",
    "1) Write a query to get one table that joins the `events` table with the `users` table (on `userid`) to create the following table.\n",
    "\n",
    "        SELECT users.userid, users.campaign_id, events.meal_id,events.event \n",
    "        FROM users \n",
    "        INNER JOIN events on users.userid = events.userid \n",
    "        LIMIT 5;\n",
    "\n",
    "\n",
    "         userid | campaign_id | meal_id | event  \n",
    "        --------+-------------+---------+--------\n",
    "              3 | FB          |      18 | bought\n",
    "              3 | FB          |      18 | bought\n",
    "              7 | PI          |       1 | like\n",
    "              7 | PI          |       1 | like\n",
    "             10 | TW          |      29 | bought\n",
    "        (5 rows)\n",
    "\n",
    "\n",
    "2) Also include information about the meal, like the `type` and the `price`. Only include the `bought` events. The result should look like this:\n",
    "\n",
    "\n",
    "        SELECT users.userid, users.campaign_id, events.meal_id, meals.type, meals.price  \n",
    "        FROM users \n",
    "        INNER JOIN events ON users.userid = events.userid \n",
    "        INNER JOIN meals ON  meals.meal_id = events.meal_id AND events.event = 'bought' \n",
    "        LIMIT 3;\n",
    "\n",
    "\n",
    "         userid | campaign_id | meal_id |   type   | price \n",
    "        --------+-------------+---------+----------+-------\n",
    "              3 | FB          |      18 | french   |     9\n",
    "             10 | TW          |      29 | italian  |    15\n",
    "             18 | TW          |      40 | japanese |    13\n",
    "             22 | RE          |      23 | mexican  |    12\n",
    "             25 | FB          |       8 | french   |    14\n",
    "             28 | TW          |      18 | french   |     9\n",
    "        (6 rows)\n",
    "\n",
    "\n",
    "3) Write a query to get how many of each type of meal were bought.\n",
    "\n",
    "\n",
    "\n",
    "        SELECT meals.type, \n",
    "        SUM(CASE WHEN event='bought' THEN 1 ELSE 0 END) AS bought  \n",
    "        FROM meals INNER JOIN events ON meals.meal_id = events.meal_id \n",
    "        GROUP BY meals.type;\n",
    "\n",
    "            type    | bought \n",
    "        ------------+--------\n",
    "         mexican    |   8792\n",
    "         french     |  16179\n",
    "         japanese   |   6921\n",
    "         italian    |  22575\n",
    "         chinese    |   6267\n",
    "         vietnamese |   3535\n",
    "        (6 rows)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Subqueries\n",
    "================================\n",
    "\n",
    "1) Write a query to get meals that are above the average meal price.\n",
    "\n",
    "        SELECT meals.* \n",
    "        FROM meals \n",
    "        WHERE meals.price >  ( select  avg(meals.price) \n",
    "        AS avg_price FROM meals) \n",
    "        LIMIT 10 ;\n",
    "        \n",
    "         meal_id |    type    |     dt     | price \n",
    "        ---------+------------+------------+-------\n",
    "               2 | chinese    | 2013-01-01 |    13\n",
    "               5 | chinese    | 2013-01-03 |    12\n",
    "               8 | french     | 2013-01-03 |    14\n",
    "               9 | italian    | 2013-01-03 |    13\n",
    "              12 | mexican    | 2013-01-03 |    12\n",
    "              15 | italian    | 2013-01-04 |    11\n",
    "              16 | italian    | 2013-01-04 |    15\n",
    "              17 | french     | 2013-01-04 |    15\n",
    "              19 | japanese   | 2013-01-04 |    11\n",
    "              21 | vietnamese | 2013-01-04 |    12\n",
    "        (10 rows)\n",
    "\n",
    "2) Write a query to get the meals that are above the average meal price *for that type*.\n",
    "\n",
    "\n",
    "         select meals.*, average.avg \n",
    "         from meals \n",
    "         join ( select meals.type,  avg(meals.price) from meals group by meals.type ) \n",
    "         as average \n",
    "         on meals.type = average.type \n",
    "         where meals.price > average.avg \n",
    "         limit 10;\n",
    "         meal_id |    type    |     dt     | price |         avg         \n",
    "        ---------+------------+------------+-------+---------------------\n",
    "               2 | chinese    | 2013-01-01 |    13 |  9.5187165775401070\n",
    "               5 | chinese    | 2013-01-03 |    12 |  9.5187165775401070\n",
    "               8 | french     | 2013-01-03 |    14 | 11.5420000000000000\n",
    "               9 | italian    | 2013-01-03 |    13 | 11.2926136363636364\n",
    "              12 | mexican    | 2013-01-03 |    12 |  9.6975945017182131\n",
    "              16 | italian    | 2013-01-04 |    15 | 11.2926136363636364\n",
    "              17 | french     | 2013-01-04 |    15 | 11.5420000000000000\n",
    "              19 | japanese   | 2013-01-04 |    11 |  9.3804878048780488\n",
    "              21 | vietnamese | 2013-01-04 |    12 |  9.2830188679245283\n",
    "              22 | italian    | 2013-01-04 |    12 | 11.2926136363636364\n",
    "        (10 rows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3) Modify the above query to give a count of the number of meals per type that are above the average price.\n",
    "\n",
    "        SELECT meals.type, COUNT(meals.type) \n",
    "        FROM meals join ( SELECT meals.type,  AVG(meals.price) \n",
    "        FROM meals GROUP BY meals.type ) AS average \n",
    "        ON meals.type = average.type \n",
    "        WHERE meals.price > average.avg \n",
    "        GROUP BY meals.type;\n",
    "            type    | count \n",
    "        ------------+-------\n",
    "         mexican    |   152\n",
    "         french     |   243\n",
    "         japanese   |    99\n",
    "         italian    |   332\n",
    "         chinese    |    95\n",
    "         vietnamese |    47\n",
    "        (6 rows)\n",
    "\n",
    "\n",
    "4) Calculate the percentage of users which come from each service. This query will look similar to #2 from aggregation functions, except you have to divide by the total number of users.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        SELECT users.campaign_id, count(users.campaign_id )/ \n",
    "        (select  cast ( count(users.campaign_id) as real) from users ) \n",
    "        AS precent  \n",
    "        FROM users \n",
    "        GROUP BY users.campaign_id;\n",
    "         campaign_id |      precent      \n",
    "        -------------+-------------------\n",
    "         RE          | 0.156046343229544\n",
    "         FB          | 0.396813902968863\n",
    "         TW          | 0.340695148443157\n",
    "         PI          | 0.106444605358436\n",
    "        (4 rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
