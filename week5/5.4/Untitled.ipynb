{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part 1: Introduction to SparkSQL\n",
    "\n",
    "SparkSQL allows you to execute relational queries on **structured** data using Spark. First you would turn a regular `RDD` into a `SchemaRDD` which then can be queried as a SQL table. Here we will be running some queries \n",
    "on a Yelp dataset.\n",
    "\n",
    "<br>\n",
    "\n",
    "1. Instantiate a `HiveContext()` and load the Yelp business data in using `jsonFile()`. \n",
    "\n",
    "   ```python\n",
    "   yelp_business_schema_rdd = hive_contxt.jsonFile('s3n://[YOUR ACCESS_KEY]:[YOUR SECRET_KEY]@sparkdatasets/yelp_academic_dataset_business.json')\n",
    "   ```\n",
    "\n",
    "2. Print the schema and register the `yelp_business_schema_rdd` as a table named `yelp_business`.\n",
    "\n",
    "3. Write a query that returns the `name` of entries that fulfill the following conditions:\n",
    "   - Rated at 5 `stars`\n",
    "   - In the city of Phoenix\n",
    "   - Accepts credit card (Reference the `Accept Credit Card` field by ````attributes.`Accepts Credit Cards`````\n",
    "   - And is under the `Restaurants` category\n",
    "\n",
    "<br>\n",
    "\n",
    "##Part 2: Spark and SparkSQL in Practice \n",
    "\n",
    "Now we have a basic knowledge of how SparkSQL works, let's try dealing with a real-life scenario where some data manipulation is required in a regular Spark RDD before querying the data with SparkSQL.\n",
    "\n",
    "<br>\n",
    "\n",
    "1. Load the `user` and `transaction` datasets into 2 separate RDDs with the following code. \n",
    "\n",
    "   ```python\n",
    "   user_rdd = sc.textFile('s3n://[YOUR ACCESS_KEY]:[YOUR SECRET_KEY]@sparkdatasets/users.txt')\n",
    "   transaction_rdd = sc.textFile('s3n://[YOUR ACCESS_KEY]:[YOUR SECRET_KEY]@sparkdatasets/transactions.txt')\n",
    "   ```\n",
    "\n",
    "2. Each row in the `user` RDD represent the user with his/her `user_id, name, email, phone`. Each row in the \n",
    "   `transaction` RDDs has the columns  `user_id, amount_paid, date`. Map functions to the RDDs to make each row in \n",
    "   the RDDs a json **string** such as `{user_id: XXX, name: XXX, email:XXX, phone:XXX}` (use `json.dumps()`).\n",
    "\n",
    "   **P.S.: Strip the `$` sign in the `amount_paid` column in the `transaction` RDD so it would be recognize as a   \n",
    "   float when read into a SchemaRDD.**\n",
    "\n",
    "3. Convert the `user` and `transaction` RDDs to SchemaRDDs. Print the schemas to make sure the conversion is \n",
    "   successful. Register the SchemaRDDs as separate tables and print the first couple of rows with SQL queries.\n",
    "\n",
    "4. Write a SQL query to return the names and the amount paid for the users with the **top 10** transaction amount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
