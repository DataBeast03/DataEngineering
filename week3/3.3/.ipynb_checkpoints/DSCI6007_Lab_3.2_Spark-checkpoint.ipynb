{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 0: Spark Installation\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these steps for installing PySpark on your laptop.\n",
    "\n",
    "1. Go to this [link](http://spark.apache.org/downloads.html). \n",
    "\n",
    "2. Select `Pre-built for Hadoop 2.4` or earlier under `Choose a\n",
    "   package type:`. (Note: This is important. Versions after Hadoop 2.4\n",
    "   have a bug and don't work with Amazon S3.)\n",
    "\n",
    "3. Download the tar package for `spark-1.4.1-bin-hadoop1.tgz`. If you\n",
    "   are not sure pick the latest version.\n",
    "\n",
    "4. Make sure you are downloading the binary version, not the source\n",
    "   version.\n",
    "\n",
    "5. Unzip the file and place it at your home directory.\n",
    "\n",
    "6. Include the following lines in your `~/.bash_profile` file on Mac\n",
    "   (without the brackets).\n",
    "\n",
    "   ```\n",
    "   export SPARK_HOME=[FULL-PATH-TO-SPARK-FOLDER]\n",
    "   export PYTHONPATH=[FULL-PATH-TO-SPARK-FOLDER]/python:$PYTHONPATH\n",
    "   ```\n",
    "\n",
    "7. Install py4j using `sudo pip install py4j`\n",
    "\n",
    "8. Open a new terminal window.\n",
    "\n",
    "9. Start ipython console and type `import pyspark as ps`. If this did\n",
    "   not throw an error, then your installation was successful.\n",
    "\n",
    "10. Start `ipython notebook` from the new terminal window.\n",
    "\n",
    "11. If PySpark throws errors about Java you might need to download the\n",
    "    newest version of the\n",
    "    [JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html).\n",
    "    \n",
    "    \n",
    "Part 1: RDD and Spark Basics\n",
    "----------------------------\n",
    "\n",
    "Lets get familiar with the basics of Spark (PySpark). We will\n",
    "be using Spark in local mode. \n",
    "\n",
    "1. Initiate a `SparkContext`. A `SparkContext` specifies where your\n",
    "   cluster is, i.e. the resources for all your distributed\n",
    "   computation. Specify your `SparkContext` as follows.\n",
    "   \n",
    "   ```python\n",
    "   import pyspark as ps\n",
    "   # Uses all 4 cores on your machine\n",
    "   sc = ps.SparkContext('local[4]') \n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = ps.SparkContext('local[4]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Spark keeps your data in **Resilient Distributed Datasets (RDDs)**.\n",
    "   **An RDD is a collection of data partitioned across machines**.\n",
    "   Each group of records that is processed by a single thread (*task*) on a\n",
    "   particular machine on a single machine is called a *partition*.\n",
    "\n",
    "   Using RDDs Spark can process your data in parallel across\n",
    "   the cluster. \n",
    "   \n",
    "   You can create an RDD from a list, from a file or from an existing\n",
    "   RDD.\n",
    "   \n",
    "   Lets create an RDD from a Python list.\n",
    "   \n",
    "   ```python\n",
    "   list_rdd = sc.parallelize([1, 2, 3])\n",
    "   ```\n",
    "   \n",
    "   Read an RDD in from a text file. **By default, the RDD will treat\n",
    "   each line as an item and read it in as string.**\n",
    "   \n",
    "   ```python\n",
    "   file_rdd = sc.textFile('data/toy_data.txt')\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_rdd = sc.parallelize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_rdd = sc.textFile('/Users/Alexander/Documents/6007_Data_Engineering/Data/toy_data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. RDDs are lazy so they do not load the data from disk unless it is\n",
    "   needed. Each RDD knows what it has to do when it is asked to\n",
    "   produce data. In addition it also has a pointer to its parent RDD\n",
    "   or a pointer to a file or a pointer to an in-memory list.\n",
    "\n",
    "   When you use `take()` or `first()` to inspect an RDD does it load\n",
    "   the entire file or just the partitions it needs to produce the\n",
    "   results? Exactly. It just loads the partitions it needs.\n",
    " \n",
    "   ```python\n",
    "   file_rdd.first() # Views the first entry\n",
    "   file_rdd.take(2) # Views the first two entries\n",
    "   ```\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{\"Jane\": \"2\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd.first() # Views the first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'{\"Jane\": \"2\"}', u'{\"Jane\": \"1\"}']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd.take(2) # Views the first two entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "4. If you want to get all the data from the partitions to be sent back\n",
    "   to the driver you can do that using `collect()`. However, if your\n",
    "   dataset is large this will kill the driver. Only do this when you\n",
    "   are developing with a small test dataset.\n",
    "   \n",
    "   ```python\n",
    "   file_rdd.collect()\n",
    "   list_rdd.collect()\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'{\"Jane\": \"2\"}',\n",
       " u'{\"Jane\": \"1\"}',\n",
       " u'{\"Pete\": \"20\"}',\n",
       " u'{\"Tyler\": \"3\"}',\n",
       " u'{\"Duncan\": \"4\"}',\n",
       " u'{\"Yuki\": \"5\"}',\n",
       " u'{\"Duncan\": \"6\"}',\n",
       " u'{\"Duncan\": \"4\"}',\n",
       " u'{\"Duncan\": \"5\"}']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Transformations and Actions\n",
    "-----------------------------------\n",
    "\n",
    "Use\n",
    "<http://real-chart.finance.yahoo.com/table.csv?s=AAPL&g=d&ignore=.csv>\n",
    "to download the most recent stock prices of AAPL, and save it to\n",
    "`aapl.csv`.\n",
    "\n",
    "        import urllib2\n",
    "        url = 'http://real-chart.finance.yahoo.com/table.csv?s=AAPL&g=d&ignore=.csv'\n",
    "        csv = urllib2.urlopen(url).read()\n",
    "        with open('aapl.csv','w') as f: f.write(csv)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "url = 'http://real-chart.finance.yahoo.com/table.csv?s=AAPL&g=d&ignore=.csv'\n",
    "csv = urllib2.urlopen(url).read()\n",
    "with open('aapl.csv','w') as f: f.write(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is\n",
    "in CSV format and has these values.\n",
    "\n",
    "Date        |Open    |High    |Low     |Close   |Volume      |Adj Close\n",
    "----        |----    |----    |---     |-----   |------      |---------\n",
    "11-18-2014  |113.94  |115.69  |113.89  |115.47  |44,200,300  |115.47\n",
    "11-17-2014  |114.27  |117.28  |113.30  |113.99  |46,746,700  |113.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = sc.textFile('aapl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Date,Open,High,Low,Close,Volume,Adj Close',\n",
       " u'2015-09-10,110.269997,113.279999,109.900002,112.57,62675200,112.57',\n",
       " u'2015-09-09,113.760002,114.019997,109.769997,110.150002,84344400,110.150002']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How many records are there in this CSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numer of records 8762\n"
     ]
    }
   ],
   "source": [
    "print \"Total numer of records {}\".format(client\\\n",
    "                                 .filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "                                 .count() ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Find the average *adjusted close* price of the stock. Also find the\n",
    "min, max, variance, and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Question about saving objects\n",
    "    How does saving objects affect memory?\n",
    "    Would it be better to minimize saved objects for speed?\n",
    "    What's the best practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average  ACP 14.3410010144\n",
      "min      ACP 0.167662\n",
      "max      ACP 131.942761\n",
      "stdev    ACP 27.6474014678\n",
      "variance ACP 764.378807924\n"
     ]
    }
   ],
   "source": [
    "adj_close = client\\\n",
    "      .filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "      .map(lambda x: x.split(\",\"))\\\n",
    "      .map(lambda (Date,Open,High,Low,Close,Volume,AdjClose): float(AdjClose))\n",
    "\n",
    "print \"average  ACP {}\".format(adj_close.mean())\n",
    "print \"min      ACP {}\".format(adj_close.min())\n",
    "print \"max      ACP {}\".format(adj_close.max())\n",
    "print \"stdev    ACP {}\".format(adj_close.stdev())\n",
    "print \"variance ACP {}\".format(adj_close.variance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Find the dates of the 3 highest adjusted close prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'2015-05-22', 131.942761),\n",
       " (u'2015-02-23', 131.849954),\n",
       " (u'2015-04-27', 131.502974)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "      .map(lambda x: x.split(\",\"))\\\n",
    "      .map(lambda (Date,Open,High,Low,Close,Volume,AdjClose): (Date,float(AdjClose)))\\\n",
    "      .sortBy(lambda (Data,AdjClose):AdjClose,ascending=False)\\\n",
    "      .take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Find the date of the 3 lowest adjusted close prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1982-07-08', 0.167662),\n",
       " (u'1982-07-09', 0.173378),\n",
       " (u'1982-07-07', 0.175283)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "      .map(lambda x: x.split(\",\"))\\\n",
    "      .map(lambda (Date,Open,High,Low,Close,Volume,AdjClose): (Date,float(AdjClose)))\\\n",
    "      .sortBy(lambda (Data,AdjClose):AdjClose,ascending=True)\\\n",
    "      .take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Find the number of days on which the stock price fell, i.e. the\n",
    "close price was lower than the open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8699"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "      .map(lambda x: x.split(\",\"))\\\n",
    "      .map(lambda (Date,Open,High,Low,Close,Volume,AdjClose): (float(Open),float(AdjClose)))\\\n",
    "      .filter(lambda (Open,AdjClose): Open > AdjClose )\\\n",
    "      .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Find the number of days on which the stock price rose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "      .map(lambda x: x.split(\",\"))\\\n",
    "      .map(lambda (Date,Open,High,Low,Close,Volume,AdjClose): (float(Open),float(AdjClose)))\\\n",
    "      .filter(lambda (Open,AdjClose): Open < AdjClose )\\\n",
    "      .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Find the number of days on which the stock price neither fell nor\n",
    "  rose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####The answer directly depends on the number of significant figures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "      .map(lambda x: x.split(\",\"))\\\n",
    "      .map(lambda (Date,Open,High,Low,Close,Volume,AdjClose): (float(Open),float(AdjClose)))\\\n",
    "      .filter(lambda (Open,AdjClose): int(Open) == int(AdjClose) )\\\n",
    "      .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Find out why we need to take logs differences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: To find out how much the stock price changed on a particular day,\n",
    "convert the close and the open prices to natural log values using\n",
    "`math.log()` and then take the difference between the close and the\n",
    "open. This gives you the log change in the price. Find the 3 days on\n",
    "which the price increased the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08338582269624606, 0.02700694933363046, 0.023988658595421875]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "      .map(lambda x: x.split(\",\"))\\\n",
    "      .map(lambda (Date,Open,High,Low,Close,Volume,AdjClose): (float(Open),float(AdjClose)))\\\n",
    "      .map(lambda (Open,Close): log(Close) - log(Open))\\\n",
    "      .sortBy(lambda diff :diff,ascending=False)\\\n",
    "      .take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: The log change price lets you calculate the average change by\n",
    "taking the average of the log changes. Calculate the average change in\n",
    "log price over the entire range of prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.972334830894987"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.filter(lambda line: not line.startswith(\"Date\"))\\\n",
    "      .map(lambda x: x.split(\",\"))\\\n",
    "      .map(lambda (Date,Open,High,Low,Close,Volume,AdjClose): (float(Open),float(AdjClose)))\\\n",
    "      .map(lambda (Open,Close): log(Close) - log(Open))\\\n",
    "      .mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Extra Credit\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Write a function that given a string date gives you the weekday.\n",
    "Here is code that calculates the weekday for 2015/05/05. This returns\n",
    "an integer. `0` is Monday, `1` is Tuesday, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Using this function calculate the weekday for all the stock prices,\n",
    "and the log change in the price on that day. Convert the log change\n",
    "back to percentage change. To convert log change to percentage take\n",
    "use `percent_change = math.exp(log_change) - 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Does the price change more on some days and less on others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
