Distributed and Scalable Data Engineering
===============================================================

* Write complex queries including joins and aggregate functions
* Define a normalized relational data model
* Process data in the cloud (*i.e.* EC2)
* Distribute embarrassingly parallel processing task across a cluster
* Use shell commands to search through files and reveal statistics
* Set up HDFS and move data in and out of HDFS
* Evaluate when it's appropriate to apply Lambda Architecture
* Define a fact-based graph schema
* Process data using Hadoop Map Reduce
* Ingest data into Spark, transform it, and write it back out again
* Use Spark to aggregate & process key-value pair
* Develop file schema and stage data for batch processing in HDFS
* Explain uses and limitations of Hive
* Employ MLlib to predict user behavior
* Develop and implement a DAG for batch processing
* Generalize batch layer methodology to a new problem
* Serve queries to the batch layer using Hive
* Use SparkSQL to query batch views
* Generalize serving layer methodology to a new problem
* Build a horizontally scalable queueing and streaming system using Kafka
* Deploy micro-batch stream processing for real-time analytics
* Identify use-cases for NoSQL
* Configure HBase to store realtime views
* Develop speed layer for realtime pageviews 
* Generalize speed layer methodology to a new problem
* Produce a complete query-able lambda architecture
* Generalize the complete lambda architecture to a new problem


--------------------------------------------------------------  
Much of the curriculum is adapted from [Big Data](http://www.manning.com/marz/) by Nathan Marz with James Warren. Much of the technology has changed since that book was written but the basic principles are the same. 

Spark and Hadoop are the technologies we will be using most throughout the course. There are many books on both (including some in our own library) that can help including [Hadoop: the Definitive Guide](http://shop.oreilly.com/product/0636920033448.do), [Learning Spark](http://shop.oreilly.com/product/0636920028512.do) and [Advanced Analytics with Spark](http://shop.oreilly.com/product/0636920035091.do). Berkeley's AMPLab also has a good [tutorial](http://ampcamp.berkeley.edu/big-data-mini-course/index.html) for Spark.

Other technologies that will be used include [PostgreSQL](http://www.postgresql.org/), [StarCluster](http://star.mit.edu/cluster/), [Avro](https://avro.apache.org/), [Hive](https://hive.apache.org/), [HBase](http://hbase.apache.org/), and [Kafka](http://kafka.apache.org/).

--------------------------------------------------------------  
1. Relational Databases and the Cloud
    1. Structured Query Language
    2. Relational Data Model
    3. Cloud Computing
    4. Cluster Computing
2. Files and File Systems
    1. Linux
    2. Hadoop Distributed File System
    3. Intro to Lambda Architecture
    4. Serialization Frameworks and Fact-Based Data Models
3. Map/Reduce and Spark
    1. Project Proposals
    2. Hadoop MapReduce
    3. Intro to Spark
    4. Spark II
4. Batch Layer
    1. Vertical Partitioning with HDFS
    2. Intro to Hive
    3. Distributed Machine Learning
    4. Generating Batch Views
5. Hive & HBase
    1. Mid-Term Review
    2. Advanced Hive
    3. Spark SQL
    4. Intro to NoSQL and HBase
6. Serving Layer
    1. Batch Layer Level Assessment
    2. Implementing the Serving Layer
    3. Queueing with Kafka
    4. Micro-batch Stream Processing with Spark
7. Speed Layer
    1. Serving Layer Level Assessment
    2. Generating Realtime Views
    3. Data Engineering in Review
    4. Speed Layer Level Asessment


